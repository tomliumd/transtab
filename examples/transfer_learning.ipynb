{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134f979d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import transtab\n",
    "\n",
    "# set random seed\n",
    "transtab.random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9b3519-1367-4092-b53d-ae640d961c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(     own_telephone  foreign_worker  duration  credit_amount  \\\n",
       "  636              0               1  0.294118       0.061957   \n",
       "  182              0               1  0.250000       0.076868   \n",
       "  736              0               1  0.294118       0.622318   \n",
       "  922              0               1  0.073529       0.061406   \n",
       "  511              1               1  0.470588       0.244085   \n",
       "  ..             ...             ...       ...            ...   \n",
       "  845              1               1  0.250000       0.205018   \n",
       "  492              0               1  0.029412       0.054308   \n",
       "  849              0               1  0.117647       0.025256   \n",
       "  297              0               0  0.088235       0.057060   \n",
       "  98               0               1  0.470588       0.114834   \n",
       "  \n",
       "       installment_commitment  residence_since       age  existing_credits  \\\n",
       "  636                1.000000         0.000000  0.160714          0.000000   \n",
       "  182                1.000000         0.333333  0.375000          0.333333   \n",
       "  736                0.000000         1.000000  0.071429          0.333333   \n",
       "  922                0.666667         1.000000  0.053571          0.000000   \n",
       "  511                0.333333         0.333333  0.232143          0.000000   \n",
       "  ..                      ...              ...       ...               ...   \n",
       "  845                0.333333         0.666667  0.285714          0.000000   \n",
       "  492                0.000000         0.000000  0.142857          0.333333   \n",
       "  849                1.000000         1.000000  0.678571          0.000000   \n",
       "  297                1.000000         0.333333  0.464286          0.000000   \n",
       "  98                 1.000000         1.000000  0.303571          0.000000   \n",
       "  \n",
       "       num_dependents checking_status                  credit_history  \\\n",
       "  636             0.0     no checking                   existing paid   \n",
       "  182             1.0              <0                        all paid   \n",
       "  736             0.0        0<=X<200                   existing paid   \n",
       "  922             0.0              <0                   existing paid   \n",
       "  511             0.0     no checking                   existing paid   \n",
       "  ..              ...             ...                             ...   \n",
       "  845             0.0        0<=X<200                   existing paid   \n",
       "  492             0.0     no checking  critical/other existing credit   \n",
       "  849             0.0              <0                   existing paid   \n",
       "  297             0.0     no checking                   existing paid   \n",
       "  98              0.0        0<=X<200  critical/other existing credit   \n",
       "  \n",
       "                   purpose    savings_status employment     personal_status  \\\n",
       "  636             radio/tv       500<=X<1000     4<=X<7  female div/dep/mar   \n",
       "  182              new car  no known savings     1<=X<4         male single   \n",
       "  736             used car              <100     1<=X<4  female div/dep/mar   \n",
       "  922             radio/tv              <100         <1  female div/dep/mar   \n",
       "  511             used car              <100     1<=X<4         male single   \n",
       "  ..                   ...               ...        ...                 ...   \n",
       "  845  furniture/equipment  no known savings     4<=X<7         male single   \n",
       "  492             radio/tv        100<=X<500     1<=X<4  female div/dep/mar   \n",
       "  849             radio/tv              <100        >=7         male single   \n",
       "  297              new car  no known savings        >=7         male single   \n",
       "  98              radio/tv              <100        >=7         male single   \n",
       "  \n",
       "      other_parties property_magnitude other_payment_plans   housing  \\\n",
       "  636          none                car                none       own   \n",
       "  182          none     life insurance                none       own   \n",
       "  736          none                car                none      rent   \n",
       "  922          none     life insurance                none      rent   \n",
       "  511          none  no known property                none  for free   \n",
       "  ..            ...                ...                 ...       ...   \n",
       "  845          none                car                none       own   \n",
       "  492          none     life insurance                none       own   \n",
       "  849          none        real estate              stores       own   \n",
       "  297  co applicant     life insurance                none       own   \n",
       "  98           none        real estate                none       own   \n",
       "  \n",
       "                             job  \n",
       "  636                    skilled  \n",
       "  182         unskilled resident  \n",
       "  736  high qualif/self emp/mgmt  \n",
       "  922                    skilled  \n",
       "  511  high qualif/self emp/mgmt  \n",
       "  ..                         ...  \n",
       "  845                    skilled  \n",
       "  492                    skilled  \n",
       "  849         unskilled resident  \n",
       "  297         unskilled resident  \n",
       "  98                     skilled  \n",
       "  \n",
       "  [700 rows x 20 columns],\n",
       "  636    1\n",
       "  182    0\n",
       "  736    0\n",
       "  922    0\n",
       "  511    1\n",
       "        ..\n",
       "  845    1\n",
       "  492    1\n",
       "  849    0\n",
       "  297    1\n",
       "  98     1\n",
       "  Length: 700, dtype: int64),\n",
       " (           A2        A3        A8       A11    A14      A15 A1 A4 A5  A6  A7  \\\n",
       "  615  0.235639  0.044643  0.008772  0.029851  0.200  0.00108  b  u  g   c   h   \n",
       "  409  0.050075  0.008929  0.011754  0.059701  0.080  0.00008  b  u  g   q   v   \n",
       "  367  0.386015  0.061071  0.005789  0.000000  0.200  0.00000  b  y  p   m   v   \n",
       "  108  0.408571  0.080357  0.350877  0.000000  0.088  0.00000  b  y  p   x   h   \n",
       "  272  0.065113  0.241071  0.001404  0.000000  0.070  0.00000  b  y  p   m   v   \n",
       "  ..        ...       ...       ...       ...    ...      ... .. .. ..  ..  ..   \n",
       "  430  0.572632  0.107143  0.052632  0.000000  0.090  0.00004  b  y  p  ff  ff   \n",
       "  477  0.382256  0.089286  0.350877  0.000000  0.100  0.00000  b  y  p   i   h   \n",
       "  27   0.644060  0.660714  0.526316  0.253731  0.000  0.00000  b  u  g   d  bb   \n",
       "  507  0.165414  0.107143  0.064386  0.283582  0.000  0.00500  a  u  g   q   h   \n",
       "  661  0.241805  0.125000  0.005789  0.000000  0.108  0.00000  b  u  g   c   v   \n",
       "  \n",
       "      A9 A10 A12 A13  \n",
       "  615  f   t   t   g  \n",
       "  409  f   t   f   g  \n",
       "  367  f   f   f   s  \n",
       "  108  t   f   t   g  \n",
       "  272  f   f   f   g  \n",
       "  ..  ..  ..  ..  ..  \n",
       "  430  f   f   f   g  \n",
       "  477  f   f   t   s  \n",
       "  27   t   t   t   g  \n",
       "  507  t   t   f   g  \n",
       "  661  f   f   f   g  \n",
       "  \n",
       "  [483 rows x 15 columns],\n",
       "  615    1\n",
       "  409    1\n",
       "  367    1\n",
       "  108    1\n",
       "  272    1\n",
       "        ..\n",
       "  430    1\n",
       "  477    1\n",
       "  27     0\n",
       "  507    0\n",
       "  661    1\n",
       "  Length: 483, dtype: int64)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c60011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/txl4827/miniconda3/envs/transtab/lib/python3.9/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml data index: 31\n",
      "load data from credit-g\n",
      "# data: 1000, # feat: 20, # cate: 11,  # bin: 2, # numerical: 7, pos rate: 0.70\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/txl4827/projects/transtab/transtab/dataset.py:208: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X[bin_cols] = X[bin_cols].astype(str).applymap(lambda x: 1 if x.lower() in ['yes','true','1','t'] else 0).values\n",
      "/home/txl4827/miniconda3/envs/transtab/lib/python3.9/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml data index: 29\n",
      "load data from credit-approval\n",
      "# data: 690, # feat: 15, # cate: 9,  # bin: 0, # numerical: 6, pos rate: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/txl4827/miniconda3/envs/transtab/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c78826b3e4b4a0f864a5b7a513d2b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test val_loss: 0.574102\n",
      "epoch: 0, train loss: 3.9759, lr: 0.000100, spent: 2.2 secs\n",
      "epoch: 1, test val_loss: 0.565162\n",
      "epoch: 1, train loss: 3.7812, lr: 0.000100, spent: 3.1 secs\n",
      "epoch: 2, test val_loss: 0.576745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 2, train loss: 3.6560, lr: 0.000100, spent: 3.9 secs\n",
      "epoch: 3, test val_loss: 0.566665\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 3, train loss: 3.6539, lr: 0.000100, spent: 4.7 secs\n",
      "epoch: 4, test val_loss: 0.548929\n",
      "epoch: 4, train loss: 3.6118, lr: 0.000100, spent: 5.7 secs\n",
      "epoch: 5, test val_loss: 0.545801\n",
      "epoch: 5, train loss: 3.5634, lr: 0.000100, spent: 6.6 secs\n",
      "epoch: 6, test val_loss: 0.545121\n",
      "epoch: 6, train loss: 3.5035, lr: 0.000100, spent: 7.5 secs\n",
      "epoch: 7, test val_loss: 0.529129\n",
      "epoch: 7, train loss: 3.4372, lr: 0.000100, spent: 8.4 secs\n",
      "epoch: 8, test val_loss: 0.525150\n",
      "epoch: 8, train loss: 3.3768, lr: 0.000100, spent: 9.2 secs\n",
      "epoch: 9, test val_loss: 0.518059\n",
      "epoch: 9, train loss: 3.3204, lr: 0.000100, spent: 10.1 secs\n",
      "epoch: 10, test val_loss: 0.508186\n",
      "epoch: 10, train loss: 3.2816, lr: 0.000100, spent: 10.9 secs\n",
      "epoch: 11, test val_loss: 0.497037\n",
      "epoch: 11, train loss: 3.1952, lr: 0.000100, spent: 11.8 secs\n",
      "epoch: 12, test val_loss: 0.495067\n",
      "epoch: 12, train loss: 3.1852, lr: 0.000100, spent: 12.7 secs\n",
      "epoch: 13, test val_loss: 0.479158\n",
      "epoch: 13, train loss: 3.0853, lr: 0.000100, spent: 13.5 secs\n",
      "epoch: 14, test val_loss: 0.492698\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 14, train loss: 3.0680, lr: 0.000100, spent: 14.2 secs\n",
      "epoch: 15, test val_loss: 0.477230\n",
      "epoch: 15, train loss: 2.9652, lr: 0.000100, spent: 15.0 secs\n",
      "epoch: 16, test val_loss: 0.503855\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 16, train loss: 2.9795, lr: 0.000100, spent: 15.8 secs\n",
      "epoch: 17, test val_loss: 0.484877\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 17, train loss: 2.9766, lr: 0.000100, spent: 16.6 secs\n",
      "epoch: 18, test val_loss: 0.467266\n",
      "epoch: 18, train loss: 2.8924, lr: 0.000100, spent: 17.4 secs\n",
      "epoch: 19, test val_loss: 0.471467\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 19, train loss: 2.8964, lr: 0.000100, spent: 18.2 secs\n",
      "epoch: 20, test val_loss: 0.460552\n",
      "epoch: 20, train loss: 2.8848, lr: 0.000100, spent: 18.9 secs\n",
      "epoch: 21, test val_loss: 0.498406\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 21, train loss: 2.8389, lr: 0.000100, spent: 19.8 secs\n",
      "epoch: 22, test val_loss: 0.441839\n",
      "epoch: 22, train loss: 2.8077, lr: 0.000100, spent: 20.5 secs\n",
      "epoch: 23, test val_loss: 0.479772\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 23, train loss: 2.8504, lr: 0.000100, spent: 21.2 secs\n",
      "epoch: 24, test val_loss: 0.450182\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 24, train loss: 2.7009, lr: 0.000100, spent: 21.9 secs\n",
      "epoch: 25, test val_loss: 0.461365\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 25, train loss: 2.7362, lr: 0.000100, spent: 22.6 secs\n",
      "epoch: 26, test val_loss: 0.481770\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 26, train loss: 2.6967, lr: 0.000100, spent: 23.3 secs\n",
      "epoch: 27, test val_loss: 0.440114\n",
      "epoch: 27, train loss: 2.7476, lr: 0.000100, spent: 24.1 secs\n",
      "epoch: 28, test val_loss: 0.450292\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 28, train loss: 2.7751, lr: 0.000100, spent: 24.8 secs\n",
      "epoch: 29, test val_loss: 0.472510\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 29, train loss: 2.6341, lr: 0.000100, spent: 25.5 secs\n",
      "epoch: 30, test val_loss: 0.438784\n",
      "epoch: 30, train loss: 2.5641, lr: 0.000100, spent: 26.3 secs\n",
      "epoch: 31, test val_loss: 0.498483\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 31, train loss: 2.7223, lr: 0.000100, spent: 27.1 secs\n",
      "epoch: 32, test val_loss: 0.463875\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 32, train loss: 2.6878, lr: 0.000100, spent: 27.9 secs\n",
      "epoch: 33, test val_loss: 0.435803\n",
      "epoch: 33, train loss: 2.6889, lr: 0.000100, spent: 28.7 secs\n",
      "epoch: 34, test val_loss: 0.495332\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 34, train loss: 2.5381, lr: 0.000100, spent: 29.6 secs\n",
      "epoch: 35, test val_loss: 0.445093\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 35, train loss: 2.5653, lr: 0.000100, spent: 30.6 secs\n",
      "epoch: 36, test val_loss: 0.449741\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 36, train loss: 2.6004, lr: 0.000100, spent: 31.5 secs\n",
      "epoch: 37, test val_loss: 0.441525\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 37, train loss: 2.5012, lr: 0.000100, spent: 32.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-07 14:48:22.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mload best at last from ./checkpoint\u001b[0m\n",
      "\u001b[32m2024-01-07 14:48:22.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1msaving model checkpoint to ./checkpoint\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, test val_loss: 0.504166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-07 14:48:22.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mtraining complete, cost 33.3 secs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load a dataset and start vanilla supervised training\n",
    "allset, trainset, valset, testset, cat_cols, num_cols, bin_cols = transtab.load_data(['credit-g', 'credit-approval'])\n",
    "\n",
    "# build transtab classifier model\n",
    "model = transtab.build_classifier(cat_cols, num_cols, bin_cols)\n",
    "\n",
    "# start training\n",
    "training_arguments = {\n",
    "    'num_epoch':50,\n",
    "    'eval_metric':'val_loss',\n",
    "    'eval_less_is_better':True,\n",
    "    'output_dir':'./checkpoint',\n",
    "    'batch_size':128,\n",
    "    'lr':1e-4,\n",
    "    'weight_decay':1e-4,\n",
    "    }\n",
    "transtab.train(model, trainset[0], valset[0], **training_arguments)\n",
    "\n",
    "# save model\n",
    "model.save('./ckpt/pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bdc971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-09 22:21:25.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m774\u001b[0m - \u001b[1mmissing keys: []\u001b[0m\n",
      "\u001b[32m2023-11-09 22:21:25.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m775\u001b[0m - \u001b[1munexpected keys: []\u001b[0m\n",
      "\u001b[32m2023-11-09 22:21:25.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m776\u001b[0m - \u001b[1mload model from ./ckpt/pretrained\u001b[0m\n",
      "\u001b[32m2023-11-09 22:21:25.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.modeling_transtab\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m222\u001b[0m - \u001b[1mload feature extractor from ./ckpt/pretrained/extractor/extractor.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# now let's use another data and try to leverage the pretrained model for finetuning\n",
    "# here we have loaded the required data `credit-approval` before, no need to load again.\n",
    "\n",
    "# load the pretrained model\n",
    "model.load('./ckpt/pretrained')\n",
    "\n",
    "# update model's categorical/numerical/binary column dict\n",
    "# need to specify the number of classes if the new dataset has different # of classes from the \n",
    "# pretrained one.\n",
    "model.update({'cat':cat_cols,'num':num_cols,'bin':bin_cols, 'num_class':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f399d02e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b389a16ead0246068791676e1c999826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test auc: 0.877056\n",
      "epoch: 0, train loss: 2.7236, lr: 0.000200, spent: 0.5 secs\n",
      "epoch: 1, test auc: 0.898701\n",
      "epoch: 1, train loss: 2.3199, lr: 0.000200, spent: 0.8 secs\n",
      "epoch: 2, test auc: 0.901299\n",
      "epoch: 2, train loss: 1.9922, lr: 0.000200, spent: 1.2 secs\n",
      "epoch: 3, test auc: 0.902165\n",
      "epoch: 3, train loss: 1.9006, lr: 0.000200, spent: 1.5 secs\n",
      "epoch: 4, test auc: 0.903030\n",
      "epoch: 4, train loss: 1.9025, lr: 0.000200, spent: 2.0 secs\n",
      "epoch: 5, test auc: 0.903896\n",
      "epoch: 5, train loss: 1.9316, lr: 0.000200, spent: 2.4 secs\n",
      "epoch: 6, test auc: 0.904762\n",
      "epoch: 6, train loss: 1.8867, lr: 0.000200, spent: 2.7 secs\n",
      "epoch: 7, test auc: 0.907359\n",
      "epoch: 7, train loss: 1.8282, lr: 0.000200, spent: 3.1 secs\n",
      "epoch: 8, test auc: 0.905628\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 8, train loss: 1.8394, lr: 0.000200, spent: 3.4 secs\n",
      "epoch: 9, test auc: 0.904762\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 9, train loss: 1.8135, lr: 0.000200, spent: 3.8 secs\n",
      "epoch: 10, test auc: 0.905628\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 10, train loss: 1.8069, lr: 0.000200, spent: 4.0 secs\n",
      "epoch: 11, test auc: 0.906494\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 11, train loss: 1.7979, lr: 0.000200, spent: 4.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-09 22:21:30.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mload best at last from ./checkpoint\u001b[0m\n",
      "\u001b[32m2023-11-09 22:21:30.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1msaving model checkpoint to ./checkpoint\u001b[0m\n",
      "\u001b[32m2023-11-09 22:21:30.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtranstab.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mtraining complete, cost 5.0 secs.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, test auc: 0.906494\n",
      "EarlyStopping counter: 5 out of 5\n",
      "early stopped\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "training_arguments = {\n",
    "    'num_epoch':50,\n",
    "    'eval_metric':'auc',\n",
    "    'eval_less_is_better':False,\n",
    "    'output_dir':'./checkpoint',\n",
    "    'batch_size':128,\n",
    "    'lr':2e-4,\n",
    "    }\n",
    "\n",
    "transtab.train(model, trainset[1], valset[1], **training_arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa87021",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "591    0\n",
      "280    1\n",
      "688    1\n",
      "345    1\n",
      "433    1\n",
      "      ..\n",
      "270    0\n",
      "640    1\n",
      "503    0\n",
      "472    1\n",
      "56     0\n",
      "Length: 138, dtype: int64\n",
      "0.8516074089844582\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "x_test, y_test = testset[1]\n",
    "ypred = transtab.predict(model, x_test, y_test)\n",
    "transtab.evaluate(ypred, y_test, metric='auc')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b67ce1a-e641-4fe8-985c-e3416a625e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "591    0\n",
      "280    1\n",
      "688    1\n",
      "345    1\n",
      "433    1\n",
      "      ..\n",
      "270    0\n",
      "640    1\n",
      "503    0\n",
      "472    1\n",
      "56     0\n",
      "Length: 138, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10238233, 0.9414178 , 0.9487131 , 0.94316643, 0.9472686 ,\n",
       "       0.6237414 , 0.94226485, 0.8916272 , 0.9362268 , 0.41641104,\n",
       "       0.12146674, 0.91955036, 0.12717126, 0.83559066, 0.28000513,\n",
       "       0.41722918, 0.4239978 , 0.35411915, 0.29504532, 0.9425222 ,\n",
       "       0.40128878, 0.311141  , 0.71771014, 0.9304242 , 0.969557  ,\n",
       "       0.9414158 , 0.21258257, 0.4463454 , 0.8610884 , 0.43519256,\n",
       "       0.7737714 , 0.7846596 , 0.11704271, 0.4133278 , 0.9501856 ,\n",
       "       0.9762373 , 0.96964204, 0.4014582 , 0.1502246 , 0.3293824 ,\n",
       "       0.7861262 , 0.969995  , 0.3781279 , 0.21768375, 0.50117564,\n",
       "       0.78088725, 0.9404731 , 0.9657596 , 0.886171  , 0.9669822 ,\n",
       "       0.82203037, 0.3309794 , 0.9524497 , 0.4305382 , 0.7775538 ,\n",
       "       0.14723192, 0.90881115, 0.4096424 , 0.12045365, 0.3447752 ,\n",
       "       0.6539435 , 0.86244327, 0.92723995, 0.38572398, 0.47441232,\n",
       "       0.90979624, 0.9692085 , 0.9273723 , 0.946693  , 0.9141363 ,\n",
       "       0.9170017 , 0.9060644 , 0.82174426, 0.9603108 , 0.6998012 ,\n",
       "       0.378178  , 0.12465042, 0.9536083 , 0.5073076 , 0.9580976 ,\n",
       "       0.47085217, 0.08676023, 0.48576602, 0.16887249, 0.36466408,\n",
       "       0.27990392, 0.31647247, 0.8556459 , 0.10658927, 0.9040972 ,\n",
       "       0.5409461 , 0.3681249 , 0.76893324, 0.37689543, 0.34968656,\n",
       "       0.8690005 , 0.45604914, 0.9526928 , 0.8658672 , 0.12179963,\n",
       "       0.95860374, 0.35852325, 0.51670176, 0.8059887 , 0.10935815,\n",
       "       0.11469106, 0.9085931 , 0.11945634, 0.77198017, 0.28511155,\n",
       "       0.1332455 , 0.1254812 , 0.88109875, 0.39745995, 0.4090046 ,\n",
       "       0.80142444, 0.925738  , 0.9380988 , 0.9570223 , 0.2830643 ,\n",
       "       0.3643412 , 0.9549183 , 0.13073802, 0.9351741 , 0.95339304,\n",
       "       0.3914021 , 0.1265325 , 0.95810926, 0.8112634 , 0.94631135,\n",
       "       0.3629838 , 0.87398046, 0.95730686, 0.9517085 , 0.84019494,\n",
       "       0.35191378, 0.95826626, 0.789612  ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transtab.predict(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea843e-2167-455e-95a3-ebdc26e230f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f00ab411e3cfe281b54106f98420bd06c3920b043d7b3741a63d2a4ac576305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
